---
title: "SDSJ 2017 taskA"
author: "Konstantin Ivanin"
date: "16 сентября 2017 г"
output:
  html_document: default
  pdf_document: default
header-includes: \usepackage[T2A]{fontenc} \usepackage[utf8]{inputenc} \usepackage[russian]{babel}
---


### Задача А: определение релевантности вопроса
В данной задаче участникам необходимо построить алгоритм, определяющий релевантность поставленных вопросов к параграфу текста. Для решения этой задачи требуется не только понимать, относится ли вопрос к параграфу, но и насколько корректно он поставлен.

Это задача бинарной классификации, в которой целевая переменная `target` принимает два значения: 0 и 1. Классу 1 соответствуют релевантные вопросы, заданные к параграфу человеком. К классу 0 относятся вопросы, либо заданные человеком к другим параграфам, либо были составлены компьютером. В качестве целевой метрики используется `ROC-AUC`.

Для решения задачи А участникам дается два файла:

1. Тренировочные 119 399 пар вопросов и параграфов `train_taskA.csv`, имеющие вид: `paragraph_id`, `question_id`, `paragraph`, `question`, `target`.
2. Тестовые 74 295 пар вопросов и параграфов `test_taskA.csv`, имеющие вид: `paragraph_id`, `question_id`, `paragraph`, `question`.

В предоставленных тренировочных и тестовых данных релевантные вопросы класса 1 были случайно выбраны из собранных вопросов и ответов. Нерелевантные примеры класса 0, составленные человеком, были получены случайным выбором вопроса к другому параграфу по той же теме. Нерелевантные вопросы класса 0, заданные компьютером, в тренировочных данных отсутствуют. Участникам необходимо самим генерировать такие вопросы для достижения лучшего качества. Также, несмотря на то, что целевая переменная target принимает два значения 0 и 1, в качестве предсказаний можно отправлять вещественные числа.

Решением задачи является `.csv` файл на основе `test_taskA.csv`, с заполненным полем `target`. Файл с решением задачи должен иметь следующий вид: `paragraph_id`, `question_id`, `target`.

[Пример решения на Python](http://nbviewer.jupyter.org/github/sberbank-ai/data-science-journey-2017/blob/master/taskA/baseline.ipynb "Ссылка на nbviewer")

[Описание метрики ROC-AUC](http://www.machinelearning.ru/wiki/index.php?title=ROC-%D0%BA%D1%80%D0%B8%D0%B2%D0%B0%D1%8F "www.machinelearning.ru")

[Материалы соревнования](https://github.com/sberbank-ai/data-science-journey-2017 "GitHub")


#### EDA
Загрузим необходимые библиотеки:
```{r, message=FALSE}
library(dstools)
library(data.table)
library(tidyverse)
library(magrittr)
library(stringr)
library(tm)
library(text2vec)
library(xgboost)
library(lightgbm)
library(stringdist)
```

Считаем данные:
```{r, message=FALSE, echo=FALSE}
train.data <- readr::read_csv('data/train_task1_latest.csv')
test.data <- readr::read_csv('data/test_task1_latest.csv')
sample.submsission <- readr::read_csv('data/sample_submission_a.csv')
```

Взглянем на данные, чтобы проверить как они загрузились:
```{r}
glimpse(train.data)
glimpse(test.data)
glimpse(sample.submsission)
```

Баланс классов `r mean(train.data$target)`.

Посмотрим на распределение количества вопросов в трейне и тесте по параграфам:
```{r}
group.train <- train.data %>% 
  group_by(paragraph_id)
group.test <- test.data %>% 
  group_by(paragraph_id)

ggplot() +
  geom_density(data = group.train, mapping = aes(paragraph_id, fill = 'train'), alpha = 1/2) +
  geom_density(data = group.test, mapping = aes(paragraph_id, fill = 'test'), alpha = 1/2) +
  scale_fill_manual(values = c('train' = 'blue', 'test' = 'red'), name = 'Densities')
```

Как видим, id параграфов пересекаются в трейне и в тесте. В дальнейшем можно будет попробовать либо использовать как категориальную фичу, либо учить модель только на пересекающихся парграфах.

Добавим столбцы с длиной вопроса и параграфа и посмотрим, как их отношение влияет на `target`:
```{r}
# train.data %<>%
#   mutate(par_len = nchar(paragraph), 
#          ques_len = nchar(question),
#          len_ratio = ques_len / par_len)
# test.data %<>%
#   mutate(par_len = nchar(paragraph), 
#          ques_len = nchar(question),
#          len_ratio = ques_len / par_len)
# train.data %>% 
#   group_by(target) %>% 
#   summarise(mean_ratio = mean(len_ratio))
```

```{r, message=FALSE, warning=FALSE, include=FALSE}
rm(group.train, group.test)
```


#### Text
Оставим в трейне только те параграфы, что есть в тесте:
```{r}
#for.resample <- train.data %>% filter(paragraph_id > max(test.data$paragraph_id))
#train.data %<>% filter(paragraph_id <= max(test.data$paragraph_id))
#train.data %<>% rbind(train.data, train.data)
#train.data %<>% rbind(train.data, train.data %>% filter(target == 1))
```

Баланс классов после удаления неиспользуемых параграфов `r mean(train.data$target)`.

Обрабатываем текст. Удаляем стоп-слова и цифры, приводим к нижнему регистру, делаем стемминг:
```{r, cache=TRUE}
text_modify <- function(txt_, sw_ = c(), stem_ = FALSE) {
  if (length(sw_) > 0) {
    txt_ %<>% removeWords(sw_)
  }
  
  txt_ %<>% str_to_lower() %>% 
    str_replace_all('ё', 'е') %>%
    str_replace_all('-', ' ') %>% 
    str_replace_all('\\(', ' ( ') %>% 
    str_replace_all('\\)', ' ) ') %>% 
    str_replace_all('[:digit:]', ' ') %>% 
    str_replace_all("[^[:alpha:]]", " ") %>% 
    removePunctuation() %>% 
    str_replace_all("\\s+", ' ')
  
  if (stem_ == TRUE) {
    # позже разобраться с кодировкой
    txt_ %<>%  enc2utf8() %>%
      system(command = '/bin/mystem -cl', intern = TRUE, input = .) %>%
      str_replace_all('[{}]', '') %>%
      str_replace_all('(\\|[^ ]+)', '') %>%
      str_replace_all('\\?', '') %>%
      str_replace_all('\\s+', ' ')
    
    # txt_ %<>%
    #   stemDocument('russian')
  }
  
  return(txt_)
}

sw.url <- 'https://raw.githubusercontent.com/stopwords-iso/stopwords-ru/master/stopwords-ru.txt'
sw <- readr::read_csv(sw.url, col_names = F)$X1

train.data$paragraph[1] # оригинал
text_modify(train.data$paragraph[1]) # обработка
text_modify(train.data$paragraph[1], sw) # обработка и удаление стоп слов
text_modify(train.data$paragraph[1], sw, T) # обработка, удаление стоп слов и стемминг

# отмодифим текстовые данные с полной обработкой
train.data$paragraph %<>% text_modify(sw, T)
train.data$question %<>% text_modify(sw, T)
test.data$paragraph %<>% text_modify(sw, T)
test.data$question %<>% text_modify(sw, T)
```


#### Feature
Добавим фичи как поиск подстроки вопроса в параграфе, от 1 до 5 слов в группе:
```{r}
subst <- function(paragraph_, question_, n = 2, ret = 'bool') {
  stopifnot(ret %in% c('bool', 'int', 'sum'))
  stopifnot(n %in% 1:5)
  if (n == 1) {
    q.split <- str_split(question_, ' ')[[1]]
    p.split <- str_split(paragraph_, ' ')[[1]]
    
  }
  if (n == 2) {
    q.split <- str_split(question_, ' ')[[1]]
    q.split <- paste(q.split, lead(q.split)) 
    p.split <- str_split(paragraph_, ' ')[[1]]
    p.split <- paste(p.split, lead(p.split)) 
  }
  if (n == 3) {
    q.split <- str_split(question_, ' ')[[1]]
    q.split <- paste(q.split, lead(q.split), lead(q.split, 2)) 
    p.split <- str_split(paragraph_, ' ')[[1]]
    p.split <- paste(p.split, lead(p.split), lead(p.split, 2)) 
  }
  if (n == 4) {
    q.split <- str_split(question_, ' ')[[1]]
    q.split <- paste(q.split, lead(q.split), lead(q.split, 2), lead(q.split, 3)) 
    p.split <- str_split(paragraph_, ' ')[[1]]
    p.split <- paste(p.split, lead(p.split), lead(p.split, 2), lead(p.split, 3)) 
  }
  if (n == 5) {
    q.split <- str_split(question_, ' ')[[1]]
    q.split <- paste(q.split, lead(q.split), lead(q.split, 2), lead(q.split, 3), lead(q.split, 4)) 
    p.split <- str_split(paragraph_, ' ')[[1]]
    p.split <- paste(p.split, lead(p.split), lead(p.split, 2), lead(p.split, 3), lead(p.split, 4)) 
  }
  
  if (ret == 'bool') return(any(q.split %in% p.split))
  if (ret == 'sum') return(sum(q.split %in% p.split))
  if (ret == 'int') return(as.integer(any(q.split %in% p.split)))
}

# количество слов в параграфе и вопросе
train.data %<>%
  mutate(par_words = sapply(str_split(paragraph, ' '), length), 
         que_words = sapply(str_split(question, ' '), length),
         ratio = que_words / par_words)
test.data %<>%
  mutate(par_words = sapply(str_split(paragraph, ' '), length), 
         que_words = sapply(str_split(question, ' '), length),
         ratio = que_words / par_words)


# количество пересекающихся слов
train.data$inter_words <- train.data %>% 
  select(paragraph, question) %>% 
  apply(1, function(x){
    subst(x[1], x[2], 1, 'sum')
  })
test.data$inter_words <- test.data %>% 
  select(paragraph, question) %>% 
  apply(1, function(x){
    subst(x[1], x[2], 1, 'sum')
  })
# отношения пересекающихся слов
train.data %<>%
  mutate(par_ratio = inter_words / par_words,
         que_ratio = inter_words / que_words,
         all_ratio = inter_words / ((par_words + que_words) / 2))
test.data %<>%
  mutate(par_ratio = inter_words / par_words,
         que_ratio = inter_words / que_words,
         all_ratio = inter_words / ((par_words + que_words) / 2))

# пересекающиеся пары слов
train.data$inter2 <- train.data %>% 
  select(paragraph, question) %>% 
  apply(1, function(x){
    subst(x[1], x[2], 2, 'sum')
  })
test.data$inter2 <- test.data %>% 
  select(paragraph, question) %>% 
  apply(1, function(x){
    subst(x[1], x[2], 2, 'sum')
  })

# пересекающиеся тройки слов
train.data$inter3 <- train.data %>% 
  select(paragraph, question) %>% 
  apply(1, function(x){
    subst(x[1], x[2], 3, 'sum')
  })
test.data$inter3 <- test.data %>% 
  select(paragraph, question) %>% 
  apply(1, function(x){
    subst(x[1], x[2], 3, 'sum')
  })

# пересекающиеся четверки слов
train.data$inter4 <- train.data %>% 
  select(paragraph, question) %>% 
  apply(1, function(x){
    subst(x[1], x[2], 4, 'sum')
  })
test.data$inter4 <- test.data %>% 
  select(paragraph, question) %>% 
  apply(1, function(x){
    subst(x[1], x[2], 4, 'sum')
  })

# пересекающиеся пятерки слов
train.data$inter5 <- train.data %>% 
  select(paragraph, question) %>% 
  apply(1, function(x){
    subst(x[1], x[2], 5, 'sum')
  })
test.data$inter5 <- test.data %>% 
  select(paragraph, question) %>% 
  apply(1, function(x){
    subst(x[1], x[2], 5, 'sum')
  })
```

Пакет `stringdist`:
```{r}
train.data %<>% 
  mutate(cos_dist = stringdist(paragraph, question, method = 'cosine'),
         lv_sim = stringsim(paragraph, question, method = 'lv'))
test.data %<>% 
  mutate(cos_dist = stringdist(paragraph, question, method = 'cosine'),
         lv_sim = stringsim(paragraph, question, method = 'lv'))
```

#### Model
Подготовим данные для построения модели:
```{r, message=FALSE}
X <- train.data %>% 
  select(-question_id, -paragraph, -question, -target, -paragraph_id)
y <- train.data$target
X_pred <- test.data %>% 
  select(-question_id, -paragraph, -question, -paragraph_id)
#X$paragraph_id <- as.factor(X$paragraph_id)
#X_pred$paragraph_id <- as.factor(X_pred$paragraph_id)
X <- ds_toSparseMatrix(X)
X_pred <- ds_toSparseMatrix(X_pred)
#dtrain <- lgb.Dataset(X, label = y, free_raw_data = FALSE)
```

```{r, eval=FALSE, include=FALSE}
# Тюним xgboost:
yf = paste0('class_', y)
yf = as.factor(yf)

xgbGrid <- expand.grid(#
  eta = 0.2,
  nrounds = seq(30, 500, 50), #
  max_depth = 4, #
  colsample_bytree = 0.8, #
  subsample = 0.8, #
  min_child_weight = 1, #
  gamma = 0 #
)
fitControl <- caret::trainControl(method = 'repeatedcv', 
                                  repeats = 3,
                                  number = 5,
                                  classProbs = TRUE,
                                  summaryFunction = caret::twoClassSummary,
                                  verboseIter = TRUE)

model <- caret::train(X, yf,
            method = 'xgbTree',
            trControl = fitControl,
            tuneGrid = xgbGrid,
            metric = 'auc')
model$bestTune

```

Параметры модели xgboost:
```{r}
k <- 1 #
param <- list(
  eta = 0.2/k,
  nround = 550*k,
  max_depth = 5,
  colsample_bytree = 1,
  subsample = 1,
  min_child_weight = 1,
  gamma = 0,
  scale_pos_weight = 2.5,
  tree_method = 'auto',
  eval_metric = 'auc',
  objective = 'binary:logistic'
)
```

Кроссвалидация и построение модели xgboost:
```{r, message=FALSE, warning=FALSE}
# cv.res <- xgb.cv(data = X, label = y, boosting = 'dart',
#                  params = param, nrounds = param$nround, nfold = 5, verbose = 1L)

model <- xgboost(
  data = X,
  label = y,
  params = param,
  boosting = 'dart',
  nrounds = param$nround,
  print_every_n = 100,
  early_stopping_rounds = 100
)
```

Предикт и запись в файл:
```{r}
sample.submsission$prediction <- predict(model, X_pred)
readr::write_csv(sample.submsission, 'data/xgb.csv')

f_imp <- xgb.importance(feature_names = colnames(X), model = model)
xgb.plot.importance(f_imp[Gain > 0.005])
```

Параметры модели lightgbm:
```{r, message=FALSE, warning=FALSE}
k <- 1
param <- list(learning_rate = 0.2/k,
              num_tree = 550*k, 
              max_depth = 7, 
              num_leaves = 1024,
              max_bin = 256,
              lambda_l1 = 0,
              lambda_l2 = 5,
              feature_fraction = 1, 
              bagging_fraction = 1, 
              bagging_freq = 6, 
              scale_pos_weight = 2.5, 
              metric = 'auc',
              objective = 'binary')
```

Кроссвалидация и построение модели lightgbm:
```{r, message=FALSE, warning=FALSE}
# cv.res <- lgb.cv(dtrain,
#                  boosting = 'dart',
#                  params = param, num_tree = param$num_tree, early_stopping_rounds = 50,
#                  nfold = 5, verbose = 1L)
lgb.unloader(wipe = T)
model <- lightgbm(data = X,
                  label = y,
                  params = param,
                  boosting = 'dart',
                  nrounds = param$num_tree,
                  early_stopping_rounds = 50,
                  verbose = 1L)
```

Предикт и запись в файл:
```{r}
sample.submsission$prediction <- predict(model, X_pred)
readr::write_csv(sample.submsission, 'data/lgb.csv')
```









